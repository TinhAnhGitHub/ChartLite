general:
  fast_dev_run: False
  seed: 42

model:
  backbone_path: google/matcha-base
  max_length: 512
  max_patches: 1024
  patch_size: 16
  len_tokenizer: ???
  pad_token_id: ???
  decoder_start_token_id: ???
  bos_token_id: ???
  max_length_generation: 512
  frozen_percentage: 0.4


train_params:
  train_bs: 2
  val_bs: 2
  max_steps: 146560 
  grad_accumulation: 8
  use_fp16_mixed: true
  num_workers: 8
  val_check_interval: 500  
  save_every_n_train_steps: 1000

  ema_enable: true
  ema_decay: 0.9999
  ema_validate_original_weights: false 
  ema_every_n_steps: 1
  ema_cpu_offload: true
  

  awp_enable: true
  awp_adv_lr: 0.01
  adv_eps: 0.001
  apply_every: 20
  
optimizer:
  lr: 5e-5
  weight_decay: 0.008
  grad_clip_value: 1.0

learning_rate_scheduler:
  warmup_pct: 0.02




metrics_tolerance:
  numeric_tolerance: 0.05
  string_tolerance: 2

outputs:
  model_dir: ./run_expr

best_ckpt:
  monitor: 'val/overall_sim_avg'
  mode: 'max'
  save_top_k: 2

early_stopping:
  monitor: 'val/overall_sim_avg'
  patience: 1000
  mode: 'max'


# total step for 1 epoch = 14656 step
# 4 epeoch = 58624
#2200  step = 0.15 epoch
#586 step = 0.04 epoch
# 146 p = 2h20
#9h10 chay dc 0.15 epoch  = 2200 step
dataset:
  parquet_dict: ./downsampled_cleaned_chartQa_plotQa_colored/data
  data_ratio: 1



wandb:
  enabled: true
  project: mga-dev-a1
  run_name: experiment-test-awp-ema2


images:
  rsz_height: 512
  rsz_width: 512


# vpn:
#   nodes: 2
#   devices : 2
#   name: matcha_t
